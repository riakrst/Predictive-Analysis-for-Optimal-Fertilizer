# -*- coding: utf-8 -*-
"""Submission 1 Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kme_36fwtk7fkL0r_VGFIcHRSFIP1z_3

# Predictive Analysis for Optimal Fertilizer

# Import Library
"""

from google.colab import files
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import gc

# data preparation
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

# model development
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score

"""# Data Understanding


Dataset yang digunakan dalam proyek ini berasal dari kompetisi Kaggle berjudul [Predicting Optimal Fertilizers - Playground Series S5E6](https://www.kaggle.com/competitions/playground-series-s5e6).  
Dataset ini berisi data kuantitatif yang bertujuan untuk memprediksi jenis pupuk (fertilizer) yang optimal berdasarkan sejumlah fitur numerik dan kategorikal.

## Data Loading
"""

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c playground-series-s5e6

!unzip playground-series-s5e6.zip

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
sample_submission = pd.read_csv('sample_submission.csv')

# Tampilkan DataFrame sample submission
sample_submission

# Tampilkan DataFrame train
train

# Tampilkan DataFrame test
test

"""Data dibagi menjadi dua bagian utama:
- `train.csv`: Data latih yang berisi 750.000 baris dan 10 kolom fitur dan label target `Fertilizer Name`.
- `test.csv`: Data uji tanpa label target berisi 250.000 baris dan 9 kolom (tanpa kolom target), yang akan digunakan untuk melakukan prediksi.
- `sample_submission.csv`: Contoh format file prediksi untuk proses submission.

# Exploratory Data Analysis
"""

# Tampilkan informasi umum tentang dataset
train.info()

"""Dari output terlihat bahwa:

- Terdapat **3 kolom dengan tipe data `object`**, yaitu:
  - `Soil Type`, `Crop Type`, dan `Fertilizer Name`.  
    Kolom-kolom ini merupakan **fitur kategorikal** (non-numerik).
- Terdapat **7 kolom dengan tipe data numerik `int64`**, yaitu:
  - `id`, `Temparature`, `Humidity`, `Moisture`, `Nitrogen`, `Potassium`, dan `Phosphorous`.  
    Kolom-kolom ini merupakan **fitur numerik** yang mengandung nilai kuantitatif dari karakteristik tanah, cuaca, dan nutrisi.
- Kolom `Fertilizer Name` adalah **target variabel** yang ingin diprediksi dalam proyek ini.
- Tidak ada kolom missing value dalam dataset

"""

train.describe()

"""- Sebagian besar fitur numerik memiliki skala dan distribusi (min–max) yang berbeda, terutama pada fitur Nitrogen (4–42), Potassium (0–19), dan Phosphorous (0–42) yang menunjukkan rentang nilai yang cukup luas dan bervariasi.

- Fitur cuaca seperti Temparature (25–38), Humidity (50–72), dan Moisture (25–65) memiliki distribusi yang relatif stabil dan normal.

- Karena skala antar fitur tidak seragam, normalisasi atau standarisasi perlu dipertimbangkan agar model dapat belajar secara seimbang dan akurat.

## Memeriksa Outliers
"""

numerical_features = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Phosphorous', 'Potassium']

# Memvisualisasikan data dengan boxplot untuk mendeteksi outliers pada fitur numerik
plt.figure(figsize=(18, 8))
for i, feature in enumerate(numerical_features, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(y=train[feature])
    plt.title(f'Boxplot {feature}')
plt.tight_layout()
plt.show()

# Deteksi outlier menggunakan IQR
for feature in numerical_features:
    Q1 = train[feature].quantile(0.25)
    Q3 = train[feature].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = train[(train[feature] < lower_bound) | (train[feature] > upper_bound)]
    print(f"{feature}:")
    print(f"  Q1 = {Q1:.3f}, Q3 = {Q3:.3f}, IQR = {IQR:.3f}")
    print(f"  Lower bound = {lower_bound:.3f}, Upper bound = {upper_bound:.3f}")
    print(f"  Jumlah outlier = {outliers.shape[0]} dari total {train.shape[0]} data\n")

"""- Tidak ditemukan outlier pada keenam fitur yang dianalisis

## Univariate Analysis

Melakukan proses analisis data dengan teknik Univariate EDA yang fokus pada satu variabel (fitur) saja untuk memahami karakteristik dasarnya. Pertama, membagi fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features.
"""

numerical_features = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Phosphorous', 'Potassium']
categorical_features = ['Soil Type', 'Crop Type', 'Fertilizer Name']

"""### Categorical Features"""

# Memvisualisasikan fitur Soil Type
feature = categorical_features[0]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

# Memvisualisasikan fitur Crop Type
feature = categorical_features[1]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

# Memvisualisasikan fitur Fertilizer Name
feature = categorical_features[2]
count = train[feature].value_counts()
percent = 100*train[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""### Numerical Feature"""

# Memvisualisasikan numerical fitur dengan Histogram
plt.figure(figsize=(18, 8))
for i, feature in enumerate(numerical_features, 1):
    plt.subplot(2, 3, i)
    sns.histplot(train[feature], bins=50, kde=True)
    plt.title(f'Histogram {feature}')
plt.tight_layout()
plt.show()

"""## Multivariate Analysis

Multivariate EDA menunjukkan hubungan antara dua atau lebih variabel pada data. Multivariate EDA yang menunjukkan hubungan antara dua variabel biasa disebut sebagai bivariate EDA.

## Categorical Features
Melihat rata-rata nilai numerik terhadap setiap kategori pada fitur kategorikal, yaitu Soil Type dan Crop Type, terhadap target klasifikasi Fertilizer Name.
"""

# Loop untuk visualisasi
for col in categorical_features:
    plt.figure(figsize=(12, 5))
    sns.countplot(x=col, hue="Fertilizer Name", data=train, palette="Set2")
    plt.title(f'Jumlah masing-masing {col} untuk setiap jenis Fertilizer')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

"""### Numerical Features
- Melihat hubungan antar fitur numerik dengan pairplot
- Mengamati korelasi antar fitur numerik menggunakan heatmap
"""

# Pairplot antar fitur numerik
sns.pairplot(train[numerical_features], diag_kind='kde')
plt.suptitle("Pairplot Fitur Numerik", y=1.02)
plt.show()

# Korelasi antar fitur numerik
plt.figure(figsize=(10, 8))
correlation_matrix = train[numerical_features].corr().round(4)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik", size=20)
plt.show()

"""# Data Preparation

## Encoding fitur kategori
Mngubah kolom kategorikal (Soil Type, Crop Type, Fertilizer Name) menjadi numerik agar bisa digunakan dalam model.

Untuk fitur:
- Gunakan One-Hot Encoding pada fitur input kategorikal.
- Gunakan Label Encoding pada target (Fertilizer_Name).
"""

# Pisahkan fitur dan target data train
X = train.drop(['id', 'Fertilizer Name'], axis=1)
y = train['Fertilizer Name']

# Encoding fitur kategorikal (Soil Type dan Crop Type) menggunakan one-hot encoding
X_encoded = pd.get_dummies(X, columns=['Soil Type', 'Crop Type'])
test_encoded = pd.get_dummies(test.drop(['id'], axis=1), columns=['Soil Type', 'Crop Type'])

# Pastikan kolom antara train dan test sama (align kolom)
X_encoded, test_encoded = X_encoded.align(test_encoded, join='left', axis=1, fill_value=0)

X_encoded

test_encoded

# Encode label (target)
le = LabelEncoder()
y_encoded = le.fit_transform(y)

"""## Standardisasi
Gunakan StandardScaler agar semua fitur numerik berada dalam skala yang sama
"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_encoded)
test_scaled = scaler.transform(test_encoded)

"""## Split Data Validasi
Untuk evaluasi MAP@3 di lokal, tidak bisa langsung mengevaluasi MAP@3 pada data test (karena label test tidak diketahui)
"""

X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

"""# Model Development

Pada tahap ini dilakukan pelatihan dan evaluasi beberapa model klasifikasi, yaitu XGBoost, Random Forest, dan LightGBM, untuk memprediksi jenis pupuk berdasarkan fitur cuaca, tanah, dan tanaman.

Dataset `train` dibagi menjadi `train` dan `validation` set untuk mengevaluasi performa model secara objektif menggunakan metrik `MAP@3`. Mean Average Precision (MAP) adalah metrik evaluasi yang digunakan untuk mengukur seberapa baik model dalam memberi peringkat label yang benar di posisi teratas dari beberapa kemungkinan,  untuk tugas klasifikasi multilabel/multiclass, berbasis ranking.

Model terbaik dipilih berdasarkan skor MAP@3 tertinggi pada data validasi dan digunakan untuk menghasilkan prediksi akhir pada data test.

## Fungsi MAP@3
"""

# Fungsi MAP@3
def mapk(actual, predicted, k=3):
    def apk(a, p, k):
       # Convert the numpy array slice to a list before using the index method
        p_list = list(p[:k])
        if a in p_list:
            return 1.0 / (p_list.index(a) + 1)
        return 0.0
    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])

"""## Fungsi evaluasi model"""

def evaluate_model(model, name):
    model.fit(X_train, y_train)
    probs = model.predict_proba(X_val)
    top_3 = np.argsort(probs, axis=1)[:, -3:][:, ::-1]
    score = mapk(y_val, top_3, k=3)
    print(f"{name:<20}: MAP@3 = {score:.4f}")
    return score

# Evaluasi semua model
scores = {}

# XGBoost Classifier
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
scores['XGBoost'] = evaluate_model(xgb_model, "XGBoost")

# Bersihkan memori
del xgb_model
gc.collect()

# RandomForest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
scores['Random Forest'] = evaluate_model(rf_model, "Random Forest")

# Bersihkan memori
del rf_model
gc.collect()

# LightGBM Classifier
lgbm_model = LGBMClassifier(n_estimators=100, random_state=42)
scores['LightGBM'] = evaluate_model(lgbm_model, "LightGBM")

# Bersihkan memori
del lgbm_model
gc.collect()

scores

"""# Prediction

## Model final

Model final dengan nilai MAP tertinggi merupakan XGBoost             : MAP@3 = 0.3307

Sehingga XGBoost akan dilatih ulang untuk proses prediksi pada data test.
"""

# Latih ulang model terbaik dengan data test
final_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
final_model.fit(X_scaled, y_encoded)

# Prediksi probabilitas untuk data test
test_probs = final_model.predict_proba(test_scaled)

# Ambil 3 label dengan probabilitas tertinggi:
top_3_preds_idx = np.argsort(test_probs, axis=1)[:, -3:][:, ::-1]  # top-3 indeks terurut
# Ubah indeks ke label asli
top_3_preds_label = le.inverse_transform(top_3_preds_idx.ravel()).reshape(top_3_preds_idx.shape)

"""# Submission.csv
Buat DataFrame submission dan simpan jadi submission.csv

"""

# Format prediksi jadi string space-delimited
submission_preds = [' '.join(row) for row in top_3_preds_label]

submission = pd.DataFrame({
    'id': test['id'],  # pastikan kolom id sesuai
    'Fertilizer Name': submission_preds
})

submission.to_csv('submission.csv', index=False)
print("submission.csv berhasil dibuat.")

submission = pd.read_csv('submission.csv')
submission